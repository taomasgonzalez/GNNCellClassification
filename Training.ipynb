{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eacdd1a",
   "metadata": {},
   "source": [
    "# Training GCN\n",
    "\n",
    "Train a Graph Neural Network with the histology + gene information.\n",
    "\n",
    "We are going to create a brain layer classifier using [Torch Geometric's GCN](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html?highlight=gcn#torch-geometric-nn-models-gcn)\n",
    "\n",
    "This notebook shows the processing steps (at a lower level, what goes below the wrappers) taken from acquiring the data to creating the dataloader and using those in a training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0c564",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "For a detailed exploration and analysis of what the data actually contains, visit the `DataAnalysis` notebook, located in the same directory as this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ffdf9",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79ac9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/projects/GNNCellClassification/dataset ~/projects/GNNCellClassification\n",
      "Don't download data: Both data and images exists\n",
      "~/projects/GNNCellClassification\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "./dataset/getdata.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4171a",
   "metadata": {},
   "source": [
    "### Actual loading + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8108b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913c178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AnnData for sample 151676 ‚Ä¶\n",
      "Loading AnnData for sample 151669 ‚Ä¶\n",
      "Loading AnnData for sample 151507 ‚Ä¶\n",
      "Loading AnnData for sample 151508 ‚Ä¶\n",
      "Loading AnnData for sample 151672 ‚Ä¶\n",
      "Loading AnnData for sample 151670 ‚Ä¶\n",
      "Loading AnnData for sample 151673 ‚Ä¶\n",
      "Loading AnnData for sample 151675 ‚Ä¶\n",
      "Loading AnnData for sample 151510 ‚Ä¶\n",
      "Loading AnnData for sample 151671 ‚Ä¶\n",
      "Loading AnnData for sample 151674 ‚Ä¶\n",
      "Loading AnnData for sample 151509 ‚Ä¶\n",
      "Loading Image for sample 151676 ‚Ä¶\n",
      "Loading Image for sample 151669 ‚Ä¶\n",
      "Loading Image for sample 151507 ‚Ä¶\n",
      "Loading Image for sample 151508 ‚Ä¶\n",
      "Loading Image for sample 151672 ‚Ä¶\n",
      "Loading Image for sample 151670 ‚Ä¶\n",
      "Loading Image for sample 151673 ‚Ä¶\n",
      "Loading Image for sample 151675 ‚Ä¶\n",
      "Loading Image for sample 151510 ‚Ä¶\n",
      "Loading Image for sample 151671 ‚Ä¶\n",
      "Loading Image for sample 151674 ‚Ä¶\n",
      "Loading Image for sample 151509 ‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "import preprocess\n",
    "import load_data\n",
    "\n",
    "data_dir, img_dir, graph_dir = \"dataset/data\", \"dataset/images\", \"out/graphs\"\n",
    "ann_data, histology_imgs = preprocess.main(data_dir, img_dir, graph_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e691cc",
   "metadata": {},
   "source": [
    "## Features used for training\n",
    "\n",
    "We are going to use the following features for training:\n",
    "\n",
    "**Edge Features**:\n",
    "- Spatial Connectivities` between spots\n",
    "- Pixel `distance` (adjusted by color)\n",
    "\n",
    "**Node Features**:\n",
    "- `UMI` count (log)\n",
    "- `Color` in the `neighbourhood` of the spot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04272538",
   "metadata": {},
   "source": [
    "## PyTorch Geometric's data structure\n",
    "\n",
    "From the official [Documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html?highlight=gcn#torch-geometric-nn-models-gcn) , we can see that:\n",
    "\n",
    "A single graph in PyG is described by an instance of `torch_geometric.data.Data`, which holds the following attributes by default:\n",
    "\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "\n",
    "- `data.edge_index`: Graph connectivity in `COO` format with shape `[2, num_edges]` and type `torch.long`\n",
    "\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "\n",
    "- `data.y`: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e296d84",
   "metadata": {},
   "source": [
    "## Creating the required data structures for training\n",
    "\n",
    "We need to convert the data to what's required by PyTorch geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83907ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2460ade",
   "metadata": {},
   "source": [
    "We randomly select which patients will be used for training, which ones for validation and which ones for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7fe14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_patients: ['151507', '151675']\n",
      "train_patients: ['151674', '151669', '151676', '151672', '151508', '151509', '151673', '151671']\n",
      "val_patients: ['151507', '151675']\n",
      "test_patients: ['151670', '151510']\n"
     ]
    }
   ],
   "source": [
    "from dataloader import train_val_test_split\n",
    "\n",
    "\n",
    "train_patients, val_patients, test_patients = train_val_test_split(ann_data=ann_data, seed=42)\n",
    "\n",
    "print(f\"train_patients: {train_patients}\")\n",
    "print(f\"val_patients: {val_patients}\")\n",
    "print(f\"test_patients: {test_patients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb65883",
   "metadata": {},
   "source": [
    "### data.edge_index\n",
    "We need to transform to a `PyTorch` tensor in `COO` format.\n",
    "Let's start with a reference patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a55bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 20052 stored elements and shape (3460, 3460)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_data['151676'].obsp['spatial_connectivities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2093cbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ann_data['151676'].obsp['spatial_connectivities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17ef8510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<COOrdinate sparse matrix of dtype 'float64'\n",
       "\twith 20052 stored elements and shape (3460, 3460)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_matrix = ann_data['151676'].obsp['spatial_connectivities'].tocoo()\n",
    "coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d336332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._coo.coo_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63168e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 151676: (3460, 3460)\n",
      "Patient 151669: (3661, 3661)\n",
      "Patient 151507: (4226, 4226)\n",
      "Patient 151508: (4384, 4384)\n",
      "Patient 151672: (4015, 4015)\n",
      "Patient 151670: (3498, 3498)\n",
      "Patient 151673: (3639, 3639)\n",
      "Patient 151675: (3592, 3592)\n",
      "Patient 151510: (4634, 4634)\n",
      "Patient 151671: (4110, 4110)\n",
      "Patient 151674: (3673, 3673)\n",
      "Patient 151509: (4789, 4789)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_coo_connections\n",
    "\n",
    "coo_connections = get_coo_connections(ann_data)\n",
    "for patient, coo in coo_connections.items():\n",
    "    print(f\"Patient {patient}: {coo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0178ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151676: torch.Size([2, 20052])\n",
      "151669: torch.Size([2, 21194])\n",
      "151507: torch.Size([2, 24770])\n",
      "151508: torch.Size([2, 25698])\n",
      "151672: torch.Size([2, 23382])\n",
      "151670: torch.Size([2, 20370])\n",
      "151673: torch.Size([2, 21124])\n",
      "151675: torch.Size([2, 20762])\n",
      "151510: torch.Size([2, 27198])\n",
      "151671: torch.Size([2, 24052])\n",
      "151674: torch.Size([2, 21258])\n",
      "151509: torch.Size([2, 28172])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_edge_indices\n",
    "\n",
    "edge_indices = get_edge_indices(coo_connections)\n",
    "\n",
    "for patient, index in edge_indices.items():\n",
    "    print(f\"{patient}: {edge_indices[patient].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0682b",
   "metadata": {},
   "source": [
    "### data.edge_attr\n",
    "Edge feature matrix with shape `[num_edges, num_edge_features]`.\n",
    "For now, only get the distances for the ones that are spatially connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e38247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151676: torch.Size([20052, 1])\n",
      "151669: torch.Size([21194, 1])\n",
      "151507: torch.Size([24770, 1])\n",
      "151508: torch.Size([25698, 1])\n",
      "151672: torch.Size([23382, 1])\n",
      "151670: torch.Size([20370, 1])\n",
      "151673: torch.Size([21124, 1])\n",
      "151675: torch.Size([20762, 1])\n",
      "151510: torch.Size([27198, 1])\n",
      "151671: torch.Size([24052, 1])\n",
      "151674: torch.Size([21258, 1])\n",
      "151509: torch.Size([28172, 1])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_edge_features\n",
    "\n",
    "edge_features = get_edge_features(ann_data, edge_indices, graph_dir)\n",
    "for patient in ann_data.keys():\n",
    "    print(f\"{patient}: {edge_features[patient].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344688e",
   "metadata": {},
   "source": [
    "### data.x\n",
    "Node feature matrix with shape `[num_nodes, num_node_features]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498c508",
   "metadata": {},
   "source": [
    "#### Normalizing UMI count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27af5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_normalized_umi_count\n",
    "\n",
    "normalized_data = get_normalized_umi_count(ann_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4dead",
   "metadata": {},
   "source": [
    "#### Reducing Dimensionality of data.x\n",
    "Apply `PCA` Principal Component Analysis on the gene expression count to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589601f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3460, 50)\n",
      "(3661, 50)\n",
      "(4226, 50)\n",
      "(4384, 50)\n",
      "(4015, 50)\n",
      "(3498, 50)\n",
      "(3639, 50)\n",
      "(3592, 50)\n",
      "(4634, 50)\n",
      "(4110, 50)\n",
      "(3673, 50)\n",
      "(4789, 50)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_pca_reduced\n",
    "\n",
    "reduced_data = get_pca_reduced(normalized_data, train_patients)\n",
    "for data in reduced_data.values():\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df58bd",
   "metadata": {},
   "source": [
    "#### Retrieving histology color information for data.x\n",
    "Add it to the data.x matrix as an extra feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3274be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances of color0, color1, color2 =  [0.00134047 0.00493318 0.00063244]\n",
      "Variances of color0, color1, color2 =  [0.00100299 0.00408081 0.00090281]\n",
      "Variances of color0, color1, color2 =  [0.00058533 0.00256631 0.00049386]\n",
      "Variances of color0, color1, color2 =  [0.00059817 0.00289116 0.00048598]\n",
      "Variances of color0, color1, color2 =  [0.00160404 0.00482472 0.00077629]\n",
      "Variances of color0, color1, color2 =  [0.00137143 0.00389194 0.00066271]\n",
      "Variances of color0, color1, color2 =  [0.00084196 0.00644021 0.00071149]\n",
      "Variances of color0, color1, color2 =  [0.00166604 0.00636242 0.00100769]\n",
      "Variances of color0, color1, color2 =  [0.00063251 0.00230641 0.00054535]\n",
      "Variances of color0, color1, color2 =  [0.00228128 0.00711623 0.00111823]\n",
      "Variances of color0, color1, color2 =  [0.00123189 0.00723225 0.00067618]\n",
      "Variances of color0, color1, color2 =  [0.00053539 0.00314728 0.00054947]\n",
      "(3460,)\n",
      "(3661,)\n",
      "(4226,)\n",
      "(4384,)\n",
      "(4015,)\n",
      "(3498,)\n",
      "(3639,)\n",
      "(3592,)\n",
      "(4634,)\n",
      "(4110,)\n",
      "(3673,)\n",
      "(4789,)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_normalized_color_avgs\n",
    "\n",
    "normalized_color_avgs = get_normalized_color_avgs(ann_data)\n",
    "\n",
    "for patient_id in normalized_color_avgs.keys():\n",
    "    print(normalized_color_avgs[patient_id].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27933ffa",
   "metadata": {},
   "source": [
    "#### Integrating UMI count + color information\n",
    "Integrate the normalized and dimensionality-reduced `UMI` count information with the `color` information to form the data.x matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3277de00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3460, 51])\n",
      "torch.Size([3661, 51])\n",
      "torch.Size([4226, 51])\n",
      "torch.Size([4384, 51])\n",
      "torch.Size([4015, 51])\n",
      "torch.Size([3498, 51])\n",
      "torch.Size([3639, 51])\n",
      "torch.Size([3592, 51])\n",
      "torch.Size([4634, 51])\n",
      "torch.Size([4110, 51])\n",
      "torch.Size([3673, 51])\n",
      "torch.Size([4789, 51])\n",
      "torch.Size([3460, 51])\n",
      "torch.Size([3661, 51])\n",
      "torch.Size([4226, 51])\n",
      "torch.Size([4384, 51])\n",
      "torch.Size([4015, 51])\n",
      "torch.Size([3498, 51])\n",
      "torch.Size([3639, 51])\n",
      "torch.Size([3592, 51])\n",
      "torch.Size([4634, 51])\n",
      "torch.Size([4110, 51])\n",
      "torch.Size([3673, 51])\n",
      "torch.Size([4789, 51])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_data_x\n",
    "\n",
    "data_x = get_data_x(ann_data, reduced_data, normalized_color_avgs)\n",
    "for patient_id in data_x.keys():\n",
    "    print(data_x[patient_id].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b7dc2",
   "metadata": {},
   "source": [
    "### data.y\n",
    "Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "\n",
    "In our case, the target is the brian layer for each node, so it's going to be of shape [num_nodes, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a91229",
   "metadata": {},
   "source": [
    "As each brain layer category is a string, we should use their values to get a tensor out of them instead. This can be easily done in AnnData:\n",
    "\n",
    "- `Layer 1` -> `0`\n",
    "- `Layer 2` -> `1`\n",
    "- `Layer 3` -> `2`\n",
    "- `Layer 4` -> `3`\n",
    "- `Layer 5` -> `4`\n",
    "- `Layer 6` -> `5`\n",
    "- `Layer WM` -> `6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6919fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer categories: AAACAAGTATCTCCCA-1    Layer3\n",
      "AAACAATCTACTAGCA-1    Layer1\n",
      "AAACACCAATAACTGC-1        WM\n",
      "AAACAGAGCGACTCCT-1    Layer3\n",
      "Name: sce.layer_guess, dtype: category\n",
      "Categories (7, object): ['Layer1', 'Layer2', 'Layer3', 'Layer4', 'Layer5', 'Layer6', 'WM']\n",
      "--------\n",
      "layer codes: AAACAAGTATCTCCCA-1    2\n",
      "AAACAATCTACTAGCA-1    0\n",
      "AAACACCAATAACTGC-1    6\n",
      "AAACAGAGCGACTCCT-1    2\n",
      "dtype: int8\n"
     ]
    }
   ],
   "source": [
    "print(\"layer categories:\" , ann_data['151676'].obs[\"sce.layer_guess\"].head(4))\n",
    "print(\"--------\")\n",
    "print(\"layer codes:\" , ann_data['151676'].obs[\"sce.layer_guess\"].cat.codes.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdd280",
   "metadata": {},
   "source": [
    "There are a few NaN s in the dataset. Convert them to a new layer for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7af21b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id: 151676\n",
      "patient_id: 151669\n",
      "patient_id: 151507\n",
      "patient_id: 151508\n",
      "patient_id: 151672\n",
      "patient_id: 151670\n",
      "patient_id: 151673\n",
      "patient_id: 151675\n",
      "patient_id: 151510\n",
      "patient_id: 151671\n",
      "patient_id: 151674\n",
      "patient_id: 151509\n",
      "tensor([2, 0, 6,  ..., 6, 5, 0])\n",
      "tensor([1, 3, 0,  ..., 3, 2, 0])\n",
      "tensor([0, 2, 0,  ..., 6, 5, 0])\n",
      "tensor([2, 0, 6,  ..., 4, 6, 0])\n",
      "tensor([2, 3, 0,  ..., 3, 3, 0])\n",
      "tensor([1, 3, 0,  ..., 3, 2, 0])\n",
      "tensor([2, 0, 6,  ..., 5, 6, 1])\n",
      "tensor([0, 2, 6,  ..., 6, 5, 6])\n",
      "tensor([0, 4, 2,  ..., 2, 5, 2])\n",
      "tensor([2, 3, 0,  ..., 2, 4, 0])\n",
      "tensor([2, 0, 6,  ..., 5, 6, 0])\n",
      "tensor([0, 2, 5,  ..., 3, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_data_y\n",
    "\n",
    "data_y = get_data_y(ann_data)\n",
    "for patient_id in data_y.keys():\n",
    "    print(data_y[patient_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544b7fe",
   "metadata": {},
   "source": [
    "## data.pos\n",
    "Node position matrix with shape [num_nodes, num_dimensions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bdce801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3460, 2])\n",
      "torch.Size([3661, 2])\n",
      "torch.Size([4226, 2])\n",
      "torch.Size([4384, 2])\n",
      "torch.Size([4015, 2])\n",
      "torch.Size([3498, 2])\n",
      "torch.Size([3639, 2])\n",
      "torch.Size([3592, 2])\n",
      "torch.Size([4634, 2])\n",
      "torch.Size([4110, 2])\n",
      "torch.Size([3673, 2])\n",
      "torch.Size([4789, 2])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_data_pos\n",
    "\n",
    "data_pos = get_data_pos(ann_data)\n",
    "for patient_id in data_pos.keys():\n",
    "    print(data_pos[patient_id].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95772931",
   "metadata": {},
   "source": [
    "## Creating the Data Loaders with all the gathered information\n",
    "One for each group:\n",
    "- Training\n",
    "- Validation\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0669721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dataloader import get_dataloaders\n",
    "\n",
    "params = yaml.safe_load(open(\"params.yaml\"))['train']\n",
    "\n",
    "patients = (train_patients, val_patients, test_patients)\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders(patients, data_x, \\\n",
    "                                                        edge_indices, edge_features, \\\n",
    "                                                        data_pos, data_y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed9087",
   "metadata": {},
   "source": [
    "### Optional: Visualize one graph\n",
    "\n",
    "Takes a lot of time to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5beecb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataloader import visualize_data\n",
    "\n",
    "\n",
    "# visualize_data(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a3df4",
   "metadata": {},
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f867441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import get_model\n",
    "\n",
    "device, model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597e0f3",
   "metadata": {},
   "source": [
    "## Optimizer, Loss and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f61776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import get_criterion, get_optimizer, get_scheduler\n",
    "\n",
    "optimizer = get_optimizer(model, params)\n",
    "criterion = get_criterion()\n",
    "scheduler = get_scheduler(optimizer, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d5864",
   "metadata": {},
   "source": [
    "## Setting experiment tracking\n",
    "\n",
    "We use [mlflow](https://mlflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43fb71e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow server started (PID 26920)\n"
     ]
    }
   ],
   "source": [
    "from mlflow_server import start_mlflow_server, stop_mlflow_server\n",
    "\n",
    "port=\"5000\"\n",
    "artifacts_dir = \"artifacts\"\n",
    "pid_file_path = \"mlflow.pid\"\n",
    "log_dir=\"logs\"\n",
    "experiment_name = \"BrainLayerClassifier\"\n",
    "\n",
    "start_mlflow_server(port=port, artifacts_dir=artifacts_dir, pid_file_path=pid_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203914d3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8463453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop\n",
      "epoch:  1\n",
      "Epoch 001 : Loss: 2.0103 | Val Loss: 2.0220 | Val Acc: 0.2540\n",
      "epoch:  2\n",
      "Epoch 002 : Loss: 1.9712 | Val Loss: 2.0103 | Val Acc: 0.2540\n",
      "üèÉ View run popular-jay-416 at: http://localhost:5000/#/experiments/1/runs/6db5669cd8e040c6a1511c769f15f53d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "from train import train_loop, start_tracking_experiment\n",
    "\n",
    "\n",
    "writer = start_tracking_experiment(exp_name=experiment_name, port=port, log_dir=log_dir)\n",
    "\n",
    "loaders = (train_loader, val_loader)\n",
    "train_loop(model, optimizer, criterion, scheduler, loaders, device, params, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212be173",
   "metadata": {},
   "source": [
    "## Stopping experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "813ab5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow server stopped (PID 26920)\n"
     ]
    }
   ],
   "source": [
    "from mlflow_server import stop_mlflow_server\n",
    "\n",
    "stop_mlflow_server(pid_file_path=pid_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general-venv)",
   "language": "python",
   "name": "general-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
