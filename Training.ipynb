{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eacdd1a",
   "metadata": {},
   "source": [
    "# Training GCN\n",
    "Train a Graph Neural Network with the histology + gene information.\n",
    "\n",
    "We are going to create a brain layer classifier using [Torch Geometric's GCN](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html?highlight=gcn#torch-geometric-nn-models-gcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0c564",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "For a detailed exploration and analysis of what the data actually contains, visit the `DataAnalysis` notebook, located in the same directory as this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ffdf9",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79ac9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/projects/GNNCellClassification/dataset ~/projects/GNNCellClassification\n",
      "Don't download data: Both data and images exists\n",
      "~/projects/GNNCellClassification\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "./dataset/getdata.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4171a",
   "metadata": {},
   "source": [
    "### Actual loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8108b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913c178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AnnData for sample 151676 …\n",
      "Loading AnnData for sample 151669 …\n",
      "Loading AnnData for sample 151507 …\n",
      "Loading AnnData for sample 151508 …\n",
      "Loading AnnData for sample 151672 …\n",
      "Loading AnnData for sample 151670 …\n",
      "Loading AnnData for sample 151673 …\n",
      "Loading AnnData for sample 151675 …\n",
      "Loading AnnData for sample 151510 …\n",
      "Loading AnnData for sample 151671 …\n",
      "Loading AnnData for sample 151674 …\n",
      "Loading AnnData for sample 151509 …\n",
      "Loading Image for sample 151676 …\n",
      "Loading Image for sample 151669 …\n",
      "Loading Image for sample 151507 …\n",
      "Loading Image for sample 151508 …\n",
      "Loading Image for sample 151672 …\n",
      "Loading Image for sample 151670 …\n",
      "Loading Image for sample 151673 …\n",
      "Loading Image for sample 151675 …\n",
      "Loading Image for sample 151510 …\n",
      "Loading Image for sample 151671 …\n",
      "Loading Image for sample 151674 …\n",
      "Loading Image for sample 151509 …\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "import preprocess\n",
    "\n",
    "data_dir, img_dir, graph_dir = \"dataset/data\", \"dataset/images\", \"out/graphs\"\n",
    "ann_data, histology_imgs = preprocess.main(data_dir, img_dir, graph_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e691cc",
   "metadata": {},
   "source": [
    "## Features used for training\n",
    "\n",
    "We are going to use the following features for training:\n",
    "\n",
    "**Edge Features**:\n",
    "- Spatial Connectivities` between spots\n",
    "- Pixel `distance` (adjusted by color)\n",
    "\n",
    "**Node Features**:\n",
    "- `UMI` count (log)\n",
    "- `Color` in the `neighbourhood` of the spot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04272538",
   "metadata": {},
   "source": [
    "## PyTorch Geometric's data structure\n",
    "\n",
    "From the official [Documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html?highlight=gcn#torch-geometric-nn-models-gcn) , we can see that:\n",
    "\n",
    "A single graph in PyG is described by an instance of `torch_geometric.data.Data`, which holds the following attributes by default:\n",
    "\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "\n",
    "- `data.edge_index`: Graph connectivity in `COO` format with shape `[2, num_edges]` and type `torch.long`\n",
    "\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "\n",
    "- `data.y`: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e296d84",
   "metadata": {},
   "source": [
    "## Creating the required data structures for training\n",
    "\n",
    "We need to convert the data to what's required by PyTorch geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83907ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb65883",
   "metadata": {},
   "source": [
    "### data.edge_index\n",
    "We need to transform to a `PyTorch` tensor in `COO` format.\n",
    "Let's start with a reference patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a55bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 20052 stored elements and shape (3460, 3460)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_data['151676'].obsp['spatial_connectivities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2093cbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ann_data['151676'].obsp['spatial_connectivities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ef8510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<COOrdinate sparse matrix of dtype 'float64'\n",
       "\twith 20052 stored elements and shape (3460, 3460)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_matrix = ann_data['151676'].obsp['spatial_connectivities'].tocoo()\n",
    "coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d336332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._coo.coo_matrix"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63168e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 151676: (3460, 3460)\n",
      "Patient 151669: (3661, 3661)\n",
      "Patient 151507: (4226, 4226)\n",
      "Patient 151508: (4384, 4384)\n",
      "Patient 151672: (4015, 4015)\n",
      "Patient 151670: (3498, 3498)\n",
      "Patient 151673: (3639, 3639)\n",
      "Patient 151675: (3592, 3592)\n",
      "Patient 151510: (4634, 4634)\n",
      "Patient 151671: (4110, 4110)\n",
      "Patient 151674: (3673, 3673)\n",
      "Patient 151509: (4789, 4789)\n"
     ]
    }
   ],
   "source": [
    "coo_connections = { patient: data.obsp['spatial_connectivities'].tocoo()  \\\n",
    "                   for patient, data in ann_data.items() }\n",
    "for patient, coo in coo_connections.items():\n",
    "    print(f\"Patient {patient}: {coo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d0178ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151676: torch.Size([2, 20052])\n",
      "151669: torch.Size([2, 21194])\n",
      "151507: torch.Size([2, 24770])\n",
      "151508: torch.Size([2, 25698])\n",
      "151672: torch.Size([2, 23382])\n",
      "151670: torch.Size([2, 20370])\n",
      "151673: torch.Size([2, 21124])\n",
      "151675: torch.Size([2, 20762])\n",
      "151510: torch.Size([2, 27198])\n",
      "151671: torch.Size([2, 24052])\n",
      "151674: torch.Size([2, 21258])\n",
      "151509: torch.Size([2, 28172])\n"
     ]
    }
   ],
   "source": [
    "edge_indices = {}\n",
    "\n",
    "for patient, coo in coo_connections.items():\n",
    "    row = torch.from_numpy(coo.row).long()\n",
    "    col = torch.from_numpy(coo.col).long()\n",
    "    edge_indices[patient] = torch.stack([row, col], dim=0)\n",
    "\n",
    "    print(f\"{patient}: {edge_indices[patient].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0682b",
   "metadata": {},
   "source": [
    "## data.edge_attr\n",
    "Edge feature matrix with shape `[num_edges, num_edge_features]`.\n",
    "For now, only get the distances for the ones that are spatially connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e38247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151676: torch.Size([20052, 1])\n",
      "151669: torch.Size([21194, 1])\n",
      "151507: torch.Size([24770, 1])\n",
      "151508: torch.Size([25698, 1])\n",
      "151672: torch.Size([23382, 1])\n",
      "151670: torch.Size([20370, 1])\n",
      "151673: torch.Size([21124, 1])\n",
      "151675: torch.Size([20762, 1])\n",
      "151510: torch.Size([27198, 1])\n",
      "151671: torch.Size([24052, 1])\n",
      "151674: torch.Size([21258, 1])\n",
      "151509: torch.Size([28172, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "edge_features = {}\n",
    "for patient in ann_data.keys():\n",
    "    filename = str(f\"{patient}_adj.npy\")\n",
    "    adj_distances = np.load(os.path.join(graph_dir, filename))\n",
    "    adj_tensor = torch.from_numpy(adj_distances)\n",
    "    row, col = edge_indices[patient]\n",
    "    distances = adj_tensor[row, col]\n",
    "    edge_features[patient] = distances.unsqueeze(1).float()\n",
    "    print(f\"{patient}: {edge_features[patient].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344688e",
   "metadata": {},
   "source": [
    "## data.x\n",
    "Node feature matrix with shape `[num_nodes, num_node_features]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "589601f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3460, 33538)\n",
      "(3661, 33538)\n",
      "(4226, 33538)\n",
      "(4384, 33538)\n",
      "(4015, 33538)\n",
      "(3498, 33538)\n",
      "(3639, 33538)\n",
      "(3592, 33538)\n",
      "(4634, 33538)\n",
      "(4110, 33538)\n",
      "(3673, 33538)\n",
      "(4789, 33538)\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "node_features = {}\n",
    "for patient, data in ann_data.items():\n",
    "    sc.pp.normalize_total(ann_data[patient])\n",
    "    sc.pp.log1p(ann_data[patient])\n",
    "\n",
    "    node_features[patient] = ann_data[patient].X.todense()\n",
    "    print(node_features[patient].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26da8f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances of color0, color1, color2 =  [0.00134047 0.00493318 0.00063244]\n",
      "Variances of color0, color1, color2 =  [0.00100299 0.00408081 0.00090281]\n",
      "Variances of color0, color1, color2 =  [0.00058533 0.00256631 0.00049386]\n",
      "Variances of color0, color1, color2 =  [0.00059817 0.00289116 0.00048598]\n",
      "Variances of color0, color1, color2 =  [0.00160404 0.00482472 0.00077629]\n",
      "Variances of color0, color1, color2 =  [0.00137143 0.00389194 0.00066271]\n",
      "Variances of color0, color1, color2 =  [0.00084196 0.00644021 0.00071149]\n",
      "Variances of color0, color1, color2 =  [0.00166604 0.00636242 0.00100769]\n",
      "Variances of color0, color1, color2 =  [0.00063251 0.00230641 0.00054535]\n",
      "Variances of color0, color1, color2 =  [0.00228128 0.00711623 0.00111823]\n",
      "Variances of color0, color1, color2 =  [0.00123189 0.00723225 0.00067618]\n",
      "Variances of color0, color1, color2 =  [0.00053539 0.00314728 0.00054947]\n"
     ]
    }
   ],
   "source": [
    "from graph import get_region_colors\n",
    "\n",
    "offsets = {'151676': 310, '151669': 276, '151507': 236, '151508': 232, '151672': 264, \\\n",
    "        '151670': 339, '151673': 260, '151675': 228, '151510': 204, '151671': 238, \\\n",
    "        '151674': 234, '151509': 220}\n",
    "thickness = 48\n",
    "\n",
    "normalized_color_avgs = {}\n",
    "for patient_id, data in ann_data.items():\n",
    "    offset = offsets[patient_id]\n",
    "    hires_scale = ann_data[patient_id].uns['spatial'][patient_id]['scalefactors']['tissue_hires_scalef']\n",
    "    spot_pixels = ann_data[patient_id].obsm['spatial'] * hires_scale\n",
    "    spot_pixels = spot_pixels.astype(int)\n",
    "    \n",
    "    image = ann_data[patient_id].uns['spatial'][patient_id]['images']['hires']\n",
    "    hires_shape = image.shape\n",
    "    assert min(hires_shape[0], hires_shape[1]) > spot_pixels.max()\n",
    "\n",
    "    flipped_image = np.flip(image, 0)\n",
    "    x_pixels = spot_pixels[:, 0]\n",
    "    y_pixels = spot_pixels[:, 1]\n",
    "    \n",
    "    normalized_color_avgs[patient_id] = get_region_colors(x_pixels, y_pixels, offset=offsets[patient_id], image=flipped_image, thickness=thickness, alpha=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general-venv)",
   "language": "python",
   "name": "general-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
