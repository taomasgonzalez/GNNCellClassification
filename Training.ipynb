{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eacdd1a",
   "metadata": {},
   "source": [
    "# Training GCN\n",
    "\n",
    "Train a Graph Neural Network with the histology + gene information.\n",
    "\n",
    "We are going to create a brain layer classifier using [Torch Geometric's GCN](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html?highlight=gcn#torch-geometric-nn-models-gcn)\n",
    "\n",
    "This notebook shows the processing steps (at a lower level, what goes below the wrappers) taken from acquiring the data to creating the dataloader and using those in a training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0c564",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "For a detailed exploration and analysis of what the data actually contains, visit the `DataAnalysis` notebook, located in the same directory as this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ffdf9",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79ac9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/projects/GNNCellClassification/dataset ~/projects/GNNCellClassification\n",
      "Downloading data if needed...\n",
      "Don't download data: Both data and images already exist\n",
      "~/projects/GNNCellClassification\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "./dataset/getdata.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4171a",
   "metadata": {},
   "source": [
    "### Actual loading + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8108b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913c178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AnnData for sample 151676 …\n",
      "Loading AnnData for sample 151669 …\n",
      "Loading AnnData for sample 151507 …\n",
      "Loading AnnData for sample 151508 …\n",
      "Loading AnnData for sample 151672 …\n",
      "Loading AnnData for sample 151670 …\n",
      "Loading AnnData for sample 151673 …\n",
      "Loading AnnData for sample 151675 …\n",
      "Loading AnnData for sample 151510 …\n",
      "Loading AnnData for sample 151671 …\n",
      "Loading AnnData for sample 151674 …\n",
      "Loading AnnData for sample 151509 …\n",
      "Loading Image for sample 151676 …\n",
      "Loading Image for sample 151669 …\n",
      "Loading Image for sample 151507 …\n",
      "Loading Image for sample 151508 …\n",
      "Loading Image for sample 151672 …\n",
      "Loading Image for sample 151670 …\n",
      "Loading Image for sample 151673 …\n",
      "Loading Image for sample 151675 …\n",
      "Loading Image for sample 151510 …\n",
      "Loading Image for sample 151671 …\n",
      "Loading Image for sample 151674 …\n",
      "Loading Image for sample 151509 …\n",
      "Creating Graphs for sample 151676 …\n",
      "Calculating adj matrix using histology image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@8.482] global loadsave.cpp:848 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances of color0, color1, color2 =  [0.00134047 0.00493318 0.00063244]\n",
      "Var of x, y, z =  99580.40478290287 115934.31450257276 115934.31589490475\n",
      "Max value:  1942.6682021906095\n",
      "Creating Graphs for sample 151669 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00100299 0.00408081 0.00090281]\n",
      "Var of x, y, z =  115055.61305404994 109785.12825823567 115055.62076952032\n",
      "Max value:  1990.445338189566\n",
      "Creating Graphs for sample 151507 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00058533 0.00256631 0.00049386]\n",
      "Var of x, y, z =  119744.2901290638 140702.3686761846 140702.35921238275\n",
      "Max value:  2613.207049095901\n",
      "Creating Graphs for sample 151508 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00059817 0.00289116 0.00048598]\n",
      "Var of x, y, z =  121008.39013112546 148803.96100264232 148803.96221282193\n",
      "Max value:  2685.33787054901\n",
      "Creating Graphs for sample 151672 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00160404 0.00482472 0.00077629]\n",
      "Var of x, y, z =  125955.08941804472 120889.49315819104 125955.0822136935\n",
      "Max value:  2040.7540693425203\n",
      "Creating Graphs for sample 151670 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00137143 0.00389194 0.00066271]\n",
      "Var of x, y, z =  117421.16966715605 96262.35166325544 117421.17944705991\n",
      "Max value:  1994.7956641598917\n",
      "Creating Graphs for sample 151673 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00084196 0.00644021 0.00071149]\n",
      "Var of x, y, z =  100566.62435006673 126180.78424892435 126180.78032585149\n",
      "Max value:  2233.4195393409327\n",
      "Creating Graphs for sample 151675 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00166604 0.00636242 0.00100769]\n",
      "Var of x, y, z =  109225.92385384682 122473.29652010654 122473.30224166339\n",
      "Max value:  2084.929972195824\n",
      "Creating Graphs for sample 151510 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00063251 0.00230641 0.00054535]\n",
      "Var of x, y, z =  138072.9741057493 146542.48700947323 146542.4728899039\n",
      "Max value:  2798.643669443764\n",
      "Creating Graphs for sample 151671 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00228128 0.00711623 0.00111823]\n",
      "Var of x, y, z =  128154.57227603435 124286.5513145198 128154.56169854588\n",
      "Max value:  1865.3166589559444\n",
      "Creating Graphs for sample 151674 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00123189 0.00723225 0.00067618]\n",
      "Var of x, y, z =  98249.27241526509 131857.30198876595 131857.3024035793\n",
      "Max value:  2136.399617973797\n",
      "Creating Graphs for sample 151509 …\n",
      "Calculating adj matrix using histology image...\n",
      "Variances of color0, color1, color2 =  [0.00053539 0.00314728 0.00054947]\n",
      "Var of x, y, z =  139970.52544816612 156512.8461309482 156512.83344561214\n",
      "Max value:  2894.1237944718246\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "import preprocess\n",
    "import load_data\n",
    "\n",
    "data_dir, img_dir, graph_dir = \"dataset/data\", \"dataset/images\", \"out/graphs\"\n",
    "ann_data, histology_imgs = preprocess.main(data_dir, img_dir, graph_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e691cc",
   "metadata": {},
   "source": [
    "## Features used for training\n",
    "\n",
    "We are going to use the following features for training:\n",
    "\n",
    "**Edge Features**:\n",
    "- Spatial Connectivities` between spots\n",
    "- Pixel `distance` (adjusted by color)\n",
    "\n",
    "**Node Features**:\n",
    "- `UMI` count (log)\n",
    "- `Color` in the `neighbourhood` of the spot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04272538",
   "metadata": {},
   "source": [
    "## PyTorch Geometric's data structure\n",
    "\n",
    "From the official [Documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html?highlight=gcn#torch-geometric-nn-models-gcn) , we can see that:\n",
    "\n",
    "A single graph in PyG is described by an instance of `torch_geometric.data.Data`, which holds the following attributes by default:\n",
    "\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "\n",
    "- `data.edge_index`: Graph connectivity in `COO` format with shape `[2, num_edges]` and type `torch.long`\n",
    "\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "\n",
    "- `data.y`: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e296d84",
   "metadata": {},
   "source": [
    "## Creating the required data structures for training\n",
    "\n",
    "We need to convert the data to what's required by PyTorch geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83907ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2460ade",
   "metadata": {},
   "source": [
    "We randomly select which patients will be used for training, which ones for validation and which ones for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7fe14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_patients: ['151507', '151675']\n",
      "train_patients: ['151674', '151669', '151676', '151672', '151508', '151509', '151673', '151671']\n",
      "val_patients: ['151507', '151675']\n",
      "test_patients: ['151670', '151510']\n"
     ]
    }
   ],
   "source": [
    "from dataloader import train_val_test_split\n",
    "\n",
    "\n",
    "train_patients, val_patients, test_patients = train_val_test_split(ann_data=ann_data, seed=42)\n",
    "\n",
    "print(f\"train_patients: {train_patients}\")\n",
    "print(f\"val_patients: {val_patients}\")\n",
    "print(f\"test_patients: {test_patients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb65883",
   "metadata": {},
   "source": [
    "### data.edge_index\n",
    "We need to transform to a `PyTorch` tensor in `COO` format.\n",
    "Let's start with a reference patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a55bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 20052 stored elements and shape (3460, 3460)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_data['151676'].obsp['spatial_connectivities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2093cbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ann_data['151676'].obsp['spatial_connectivities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17ef8510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<COOrdinate sparse matrix of dtype 'float64'\n",
       "\twith 20052 stored elements and shape (3460, 3460)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_matrix = ann_data['151676'].obsp['spatial_connectivities'].tocoo()\n",
    "coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d336332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._coo.coo_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63168e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 151676: (3460, 3460)\n",
      "Patient 151669: (3661, 3661)\n",
      "Patient 151507: (4226, 4226)\n",
      "Patient 151508: (4384, 4384)\n",
      "Patient 151672: (4015, 4015)\n",
      "Patient 151670: (3498, 3498)\n",
      "Patient 151673: (3639, 3639)\n",
      "Patient 151675: (3592, 3592)\n",
      "Patient 151510: (4634, 4634)\n",
      "Patient 151671: (4110, 4110)\n",
      "Patient 151674: (3673, 3673)\n",
      "Patient 151509: (4789, 4789)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_coo_connections\n",
    "\n",
    "coo_connections = get_coo_connections(ann_data)\n",
    "for patient, coo in coo_connections.items():\n",
    "    print(f\"Patient {patient}: {coo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0178ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151676: torch.Size([2, 20052])\n",
      "151669: torch.Size([2, 21194])\n",
      "151507: torch.Size([2, 24770])\n",
      "151508: torch.Size([2, 25698])\n",
      "151672: torch.Size([2, 23382])\n",
      "151670: torch.Size([2, 20370])\n",
      "151673: torch.Size([2, 21124])\n",
      "151675: torch.Size([2, 20762])\n",
      "151510: torch.Size([2, 27198])\n",
      "151671: torch.Size([2, 24052])\n",
      "151674: torch.Size([2, 21258])\n",
      "151509: torch.Size([2, 28172])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_edge_indices\n",
    "\n",
    "edge_indices = get_edge_indices(coo_connections)\n",
    "\n",
    "for patient, index in edge_indices.items():\n",
    "    print(f\"{patient}: {edge_indices[patient].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0682b",
   "metadata": {},
   "source": [
    "### data.edge_attr\n",
    "Edge feature matrix with shape `[num_edges, num_edge_features]`.\n",
    "For now, only get the distances for the ones that are spatially connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e38247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151676: torch.Size([20052, 1])\n",
      "151669: torch.Size([21194, 1])\n",
      "151507: torch.Size([24770, 1])\n",
      "151508: torch.Size([25698, 1])\n",
      "151672: torch.Size([23382, 1])\n",
      "151670: torch.Size([20370, 1])\n",
      "151673: torch.Size([21124, 1])\n",
      "151675: torch.Size([20762, 1])\n",
      "151510: torch.Size([27198, 1])\n",
      "151671: torch.Size([24052, 1])\n",
      "151674: torch.Size([21258, 1])\n",
      "151509: torch.Size([28172, 1])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_edge_features\n",
    "\n",
    "edge_features = get_edge_features(ann_data, edge_indices, graph_dir)\n",
    "for patient in ann_data.keys():\n",
    "    print(f\"{patient}: {edge_features[patient].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344688e",
   "metadata": {},
   "source": [
    "### data.x\n",
    "Node feature matrix with shape `[num_nodes, num_node_features]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498c508",
   "metadata": {},
   "source": [
    "#### Normalizing UMI count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27af5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_normalized_umi_count\n",
    "\n",
    "normalized_data = get_normalized_umi_count(ann_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4dead",
   "metadata": {},
   "source": [
    "#### Reducing Dimensionality of data.x\n",
    "Apply `PCA` Principal Component Analysis on the gene expression count to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589601f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3460, 55)\n",
      "(3661, 55)\n",
      "(4226, 55)\n",
      "(4384, 55)\n",
      "(4015, 55)\n",
      "(3498, 55)\n",
      "(3639, 55)\n",
      "(3592, 55)\n",
      "(4634, 55)\n",
      "(4110, 55)\n",
      "(3673, 55)\n",
      "(4789, 55)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_pca_reduced\n",
    "\n",
    "reduced_data = get_pca_reduced(normalized_data, train_patients, n_components=55)\n",
    "for data in reduced_data.values():\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df58bd",
   "metadata": {},
   "source": [
    "#### Retrieving histology color information for data.x\n",
    "Add it to the data.x matrix as an extra feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3274be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances of color0, color1, color2 =  [0.00134047 0.00493318 0.00063244]\n",
      "Variances of color0, color1, color2 =  [0.00100299 0.00408081 0.00090281]\n",
      "Variances of color0, color1, color2 =  [0.00058533 0.00256631 0.00049386]\n",
      "Variances of color0, color1, color2 =  [0.00059817 0.00289116 0.00048598]\n",
      "Variances of color0, color1, color2 =  [0.00160404 0.00482472 0.00077629]\n",
      "Variances of color0, color1, color2 =  [0.00137143 0.00389194 0.00066271]\n",
      "Variances of color0, color1, color2 =  [0.00084196 0.00644021 0.00071149]\n",
      "Variances of color0, color1, color2 =  [0.00166604 0.00636242 0.00100769]\n",
      "Variances of color0, color1, color2 =  [0.00063251 0.00230641 0.00054535]\n",
      "Variances of color0, color1, color2 =  [0.00228128 0.00711623 0.00111823]\n",
      "Variances of color0, color1, color2 =  [0.00123189 0.00723225 0.00067618]\n",
      "Variances of color0, color1, color2 =  [0.00053539 0.00314728 0.00054947]\n",
      "(3460,)\n",
      "(3661,)\n",
      "(4226,)\n",
      "(4384,)\n",
      "(4015,)\n",
      "(3498,)\n",
      "(3639,)\n",
      "(3592,)\n",
      "(4634,)\n",
      "(4110,)\n",
      "(3673,)\n",
      "(4789,)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_normalized_color_avgs\n",
    "\n",
    "normalized_color_avgs = get_normalized_color_avgs(ann_data)\n",
    "\n",
    "for patient_id in normalized_color_avgs.keys():\n",
    "    print(normalized_color_avgs[patient_id].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27933ffa",
   "metadata": {},
   "source": [
    "#### Integrating UMI count + color information\n",
    "Integrate the normalized and dimensionality-reduced `UMI` count information with the `color` information to form the data.x matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3277de00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3460, 56])\n",
      "torch.Size([3661, 56])\n",
      "torch.Size([4226, 56])\n",
      "torch.Size([4384, 56])\n",
      "torch.Size([4015, 56])\n",
      "torch.Size([3498, 56])\n",
      "torch.Size([3639, 56])\n",
      "torch.Size([3592, 56])\n",
      "torch.Size([4634, 56])\n",
      "torch.Size([4110, 56])\n",
      "torch.Size([3673, 56])\n",
      "torch.Size([4789, 56])\n",
      "torch.Size([3460, 56])\n",
      "torch.Size([3661, 56])\n",
      "torch.Size([4226, 56])\n",
      "torch.Size([4384, 56])\n",
      "torch.Size([4015, 56])\n",
      "torch.Size([3498, 56])\n",
      "torch.Size([3639, 56])\n",
      "torch.Size([3592, 56])\n",
      "torch.Size([4634, 56])\n",
      "torch.Size([4110, 56])\n",
      "torch.Size([3673, 56])\n",
      "torch.Size([4789, 56])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_data_x\n",
    "\n",
    "data_x = get_data_x(ann_data, reduced_data, normalized_color_avgs)\n",
    "for patient_id in data_x.keys():\n",
    "    print(data_x[patient_id].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b7dc2",
   "metadata": {},
   "source": [
    "### data.y\n",
    "Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "\n",
    "In our case, the target is the brian layer for each node, so it's going to be of shape [num_nodes, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a91229",
   "metadata": {},
   "source": [
    "As each brain layer category is a string, we should use their values to get a tensor out of them instead. This can be easily done in AnnData:\n",
    "\n",
    "- `Layer 1` -> `0`\n",
    "- `Layer 2` -> `1`\n",
    "- `Layer 3` -> `2`\n",
    "- `Layer 4` -> `3`\n",
    "- `Layer 5` -> `4`\n",
    "- `Layer 6` -> `5`\n",
    "- `Layer WM` -> `6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6919fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer categories: AAACAAGTATCTCCCA-1    Layer3\n",
      "AAACAATCTACTAGCA-1    Layer1\n",
      "AAACACCAATAACTGC-1        WM\n",
      "AAACAGAGCGACTCCT-1    Layer3\n",
      "Name: sce.layer_guess, dtype: category\n",
      "Categories (7, object): ['Layer1', 'Layer2', 'Layer3', 'Layer4', 'Layer5', 'Layer6', 'WM']\n",
      "--------\n",
      "layer codes: AAACAAGTATCTCCCA-1    2\n",
      "AAACAATCTACTAGCA-1    0\n",
      "AAACACCAATAACTGC-1    6\n",
      "AAACAGAGCGACTCCT-1    2\n",
      "dtype: int8\n"
     ]
    }
   ],
   "source": [
    "print(\"layer categories:\" , ann_data['151676'].obs[\"sce.layer_guess\"].head(4))\n",
    "print(\"--------\")\n",
    "print(\"layer codes:\" , ann_data['151676'].obs[\"sce.layer_guess\"].cat.codes.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdd280",
   "metadata": {},
   "source": [
    "There are a few NaN s in the dataset. Convert them to a new layer for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7af21b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id: 151676\n",
      "patient_id: 151669\n",
      "patient_id: 151507\n",
      "patient_id: 151508\n",
      "patient_id: 151672\n",
      "patient_id: 151670\n",
      "patient_id: 151673\n",
      "patient_id: 151675\n",
      "patient_id: 151510\n",
      "patient_id: 151671\n",
      "patient_id: 151674\n",
      "patient_id: 151509\n",
      "tensor([2, 0, 6,  ..., 6, 5, 0])\n",
      "tensor([1, 3, 0,  ..., 3, 2, 0])\n",
      "tensor([0, 2, 0,  ..., 6, 5, 0])\n",
      "tensor([2, 0, 6,  ..., 4, 6, 0])\n",
      "tensor([2, 3, 0,  ..., 3, 3, 0])\n",
      "tensor([1, 3, 0,  ..., 3, 2, 0])\n",
      "tensor([2, 0, 6,  ..., 5, 6, 1])\n",
      "tensor([0, 2, 6,  ..., 6, 5, 6])\n",
      "tensor([0, 4, 2,  ..., 2, 5, 2])\n",
      "tensor([2, 3, 0,  ..., 2, 4, 0])\n",
      "tensor([2, 0, 6,  ..., 5, 6, 0])\n",
      "tensor([0, 2, 5,  ..., 3, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_data_y\n",
    "\n",
    "data_y = get_data_y(ann_data)\n",
    "for patient_id in data_y.keys():\n",
    "    print(data_y[patient_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544b7fe",
   "metadata": {},
   "source": [
    "## data.pos\n",
    "Node position matrix with shape [num_nodes, num_dimensions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bdce801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3460, 2])\n",
      "torch.Size([3661, 2])\n",
      "torch.Size([4226, 2])\n",
      "torch.Size([4384, 2])\n",
      "torch.Size([4015, 2])\n",
      "torch.Size([3498, 2])\n",
      "torch.Size([3639, 2])\n",
      "torch.Size([3592, 2])\n",
      "torch.Size([4634, 2])\n",
      "torch.Size([4110, 2])\n",
      "torch.Size([3673, 2])\n",
      "torch.Size([4789, 2])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_data_pos\n",
    "\n",
    "data_pos = get_data_pos(ann_data)\n",
    "for patient_id in data_pos.keys():\n",
    "    print(data_pos[patient_id].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95772931",
   "metadata": {},
   "source": [
    "## Creating the Data Loaders with all the gathered information\n",
    "One for each group:\n",
    "- Training\n",
    "- Validation\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0669721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dataloader import get_dataloaders\n",
    "\n",
    "params = yaml.safe_load(open(\"params.yaml\"))['train']\n",
    "\n",
    "patients = (train_patients, val_patients, test_patients)\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders(patients, data_x, \\\n",
    "                                                        edge_indices, edge_features, \\\n",
    "                                                        data_pos, data_y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9912cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31731\n",
      "0        Layer I      8631     27.20%\n",
      "1        Layer II     2541     8.01%\n",
      "2        Layer III    7977     25.14%\n",
      "3        Layer IV     3494     11.01%\n",
      "4        Layer V      4121     12.99%\n",
      "5        Layer VI     2831     8.92%\n",
      "6        White Matter 2037     6.42%\n",
      "7        Unknown      99       0.31%\n"
     ]
    }
   ],
   "source": [
    "num_classes = 8\n",
    "layer_names = ['Layer I', 'Layer II', 'Layer III', 'Layer IV', 'Layer V', 'Layer VI', 'White Matter', 'Unknown']\n",
    "\n",
    "def class_ocurrences(loader, num_classes):\n",
    "    class_counts = torch.zeros(num_classes, dtype=torch.long)\n",
    "\n",
    "    for batch in loader:\n",
    "        class_counts += torch.bincount(batch.y, minlength=num_classes)\n",
    "\n",
    "    total_samples = class_counts.sum().item()\n",
    "    print(total_samples)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        count = class_counts[i].item()\n",
    "        percentage = (count / total_samples) * 100\n",
    "        print(f\"{i:<8} {layer_names[i]:<12} {count:<8} {percentage:.2f}%\")\n",
    "\n",
    "        \n",
    "class_ocurrences(train_loader, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed9087",
   "metadata": {},
   "source": [
    "### Optional: Visualize one graph\n",
    "\n",
    "Takes a lot of time to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5beecb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataloader import visualize_data\n",
    "\n",
    "\n",
    "# visualize_data(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a3df4",
   "metadata": {},
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f867441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import get_model\n",
    "\n",
    "with open('params.yaml') as parfile:\n",
    "    all_params = yaml.safe_load(parfile)\n",
    "    featurize_params = all_params['featurize']\n",
    "    train_params = all_params['train']\n",
    "    train_params['pca_components'] = featurize_params['pca_components']\n",
    "    train_params['seed'] = featurize_params['seed']\n",
    "    tracking_params = all_params['tracking']\n",
    "\n",
    "device, model = get_model(train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597e0f3",
   "metadata": {},
   "source": [
    "## Optimizer, Loss and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07f61776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import get_criterion, get_optimizer, get_scheduler\n",
    "\n",
    "# obtain class frequencies\n",
    "class_counts = torch.zeros(model.num_classes, dtype=torch.long)\n",
    "for batch in train_loader:\n",
    "    class_counts += torch.bincount(batch.y, minlength=model.num_classes)\n",
    "total = class_counts.sum().item()\n",
    "class_freqs = class_counts.float() / total\n",
    "class_freqs = class_freqs.to(device)\n",
    "\n",
    "optimizer = get_optimizer(model, train_params)\n",
    "criterion = get_criterion(class_freqs, train_params)\n",
    "scheduler = get_scheduler(optimizer, train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d5864",
   "metadata": {},
   "source": [
    "## Setting experiment tracking\n",
    "\n",
    "We use [mlflow](https://mlflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43fb71e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow server started (PID 234060)\n"
     ]
    }
   ],
   "source": [
    "from mlflow_server import start_mlflow_server, stop_mlflow_server\n",
    "\n",
    "port=\"5000\"\n",
    "artifacts_dir = \"artifacts\"\n",
    "pid_file_path = \"mlflow.pid\"\n",
    "log_dir=\"logs\"\n",
    "experiment_name = \"BrainLayerClassifier\"\n",
    "\n",
    "start_mlflow_server(port=port, artifacts_dir=artifacts_dir, pid_file_path=pid_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203914d3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8463453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomgon01/projects/venv/lib/python3.12/site-packages/torcheval/metrics/functional/classification/accuracy.py:275: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:232.)\n",
      "  num_correct = mask.new_zeros(num_classes).scatter_(0, target, mask, reduce=\"add\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 : Loss: 2.2319 | Val Loss: 2.0663 | Val Acc: 0.1197\n",
      "epoch:  2\n",
      "Epoch 002 : Loss: 2.1322 | Val Loss: 2.0384 | Val Acc: 0.1537\n",
      "epoch:  3\n",
      "Epoch 003 : Loss: 2.1098 | Val Loss: 2.0293 | Val Acc: 0.1054\n",
      "epoch:  4\n",
      "Epoch 004 : Loss: 2.0873 | Val Loss: 2.0190 | Val Acc: 0.0950\n",
      "epoch:  5\n",
      "Epoch 005 : Loss: 2.0663 | Val Loss: 2.0100 | Val Acc: 0.0979\n",
      "epoch:  6\n",
      "Epoch 006 : Loss: 2.0463 | Val Loss: 2.0011 | Val Acc: 0.1343\n",
      "epoch:  7\n",
      "Epoch 007 : Loss: 2.0235 | Val Loss: 1.9901 | Val Acc: 0.2128\n",
      "epoch:  8\n",
      "Epoch 008 : Loss: 1.9968 | Val Loss: 1.9762 | Val Acc: 0.2751\n",
      "epoch:  9\n",
      "Epoch 009 : Loss: 1.9687 | Val Loss: 1.9580 | Val Acc: 0.2666\n",
      "epoch:  10\n",
      "Epoch 010 : Loss: 1.9505 | Val Loss: 1.9379 | Val Acc: 0.2168\n",
      "epoch:  11\n",
      "Epoch 011 : Loss: 1.9440 | Val Loss: 1.9184 | Val Acc: 0.2260\n",
      "epoch:  12\n",
      "Epoch 012 : Loss: 1.9118 | Val Loss: 1.8988 | Val Acc: 0.2583\n",
      "epoch:  13\n",
      "Epoch 013 : Loss: 1.8935 | Val Loss: 1.8781 | Val Acc: 0.3086\n",
      "epoch:  14\n",
      "Epoch 014 : Loss: 1.8825 | Val Loss: 1.8561 | Val Acc: 0.3585\n",
      "epoch:  15\n",
      "Epoch 015 : Loss: 1.8633 | Val Loss: 1.8328 | Val Acc: 0.3715\n",
      "epoch:  16\n",
      "Epoch 016 : Loss: 1.8391 | Val Loss: 1.8103 | Val Acc: 0.3571\n",
      "epoch:  17\n",
      "Epoch 017 : Loss: 1.8118 | Val Loss: 1.7885 | Val Acc: 0.3272\n",
      "epoch:  18\n",
      "Epoch 018 : Loss: 1.8057 | Val Loss: 1.7691 | Val Acc: 0.3076\n",
      "epoch:  19\n",
      "Epoch 019 : Loss: 1.7821 | Val Loss: 1.7518 | Val Acc: 0.3143\n",
      "epoch:  20\n",
      "Epoch 020 : Loss: 1.7586 | Val Loss: 1.7363 | Val Acc: 0.3396\n",
      "epoch:  21\n",
      "Epoch 021 : Loss: 1.7401 | Val Loss: 1.7219 | Val Acc: 0.3810\n",
      "epoch:  22\n",
      "Epoch 022 : Loss: 1.7116 | Val Loss: 1.7080 | Val Acc: 0.4250\n",
      "epoch:  23\n",
      "Epoch 023 : Loss: 1.7081 | Val Loss: 1.6950 | Val Acc: 0.4547\n",
      "epoch:  24\n",
      "Epoch 024 : Loss: 1.6829 | Val Loss: 1.6825 | Val Acc: 0.4632\n",
      "epoch:  25\n",
      "Epoch 025 : Loss: 1.6602 | Val Loss: 1.6715 | Val Acc: 0.4583\n",
      "epoch:  26\n",
      "Epoch 026 : Loss: 1.6707 | Val Loss: 1.6611 | Val Acc: 0.4464\n",
      "epoch:  27\n",
      "Epoch 027 : Loss: 1.6356 | Val Loss: 1.6509 | Val Acc: 0.4381\n",
      "epoch:  28\n",
      "Epoch 028 : Loss: 1.6276 | Val Loss: 1.6414 | Val Acc: 0.4289\n",
      "epoch:  29\n",
      "Epoch 029 : Loss: 1.6158 | Val Loss: 1.6325 | Val Acc: 0.4193\n",
      "epoch:  30\n",
      "Epoch 030 : Loss: 1.6037 | Val Loss: 1.6251 | Val Acc: 0.4088\n",
      "epoch:  31\n",
      "Epoch 031 : Loss: 1.5986 | Val Loss: 1.6181 | Val Acc: 0.4074\n",
      "epoch:  32\n",
      "Epoch 032 : Loss: 1.5903 | Val Loss: 1.6117 | Val Acc: 0.4051\n",
      "epoch:  33\n",
      "Epoch 033 : Loss: 1.5801 | Val Loss: 1.6061 | Val Acc: 0.4068\n",
      "epoch:  34\n",
      "Epoch 034 : Loss: 1.5736 | Val Loss: 1.6012 | Val Acc: 0.4098\n",
      "epoch:  35\n",
      "Epoch 035 : Loss: 1.5777 | Val Loss: 1.5964 | Val Acc: 0.4151\n",
      "epoch:  36\n",
      "Epoch 036 : Loss: 1.5457 | Val Loss: 1.5923 | Val Acc: 0.4203\n",
      "epoch:  37\n",
      "Epoch 037 : Loss: 1.5466 | Val Loss: 1.5891 | Val Acc: 0.4249\n",
      "epoch:  38\n",
      "Epoch 038 : Loss: 1.5479 | Val Loss: 1.5865 | Val Acc: 0.4290\n",
      "epoch:  39\n",
      "Epoch 039 : Loss: 1.5361 | Val Loss: 1.5841 | Val Acc: 0.4331\n",
      "epoch:  40\n",
      "Epoch 040 : Loss: 1.5262 | Val Loss: 1.5822 | Val Acc: 0.4359\n",
      "epoch:  41\n",
      "Epoch 041 : Loss: 1.5328 | Val Loss: 1.5808 | Val Acc: 0.4364\n",
      "epoch:  42\n",
      "Epoch 042 : Loss: 1.5301 | Val Loss: 1.5796 | Val Acc: 0.4359\n",
      "epoch:  43\n",
      "Epoch 043 : Loss: 1.5286 | Val Loss: 1.5785 | Val Acc: 0.4360\n",
      "epoch:  44\n",
      "Epoch 044 : Loss: 1.5192 | Val Loss: 1.5776 | Val Acc: 0.4371\n",
      "epoch:  45\n",
      "Epoch 045 : Loss: 1.5315 | Val Loss: 1.5769 | Val Acc: 0.4366\n",
      "epoch:  46\n",
      "Epoch 046 : Loss: 1.5104 | Val Loss: 1.5764 | Val Acc: 0.4368\n",
      "epoch:  47\n",
      "Epoch 047 : Loss: 1.5141 | Val Loss: 1.5761 | Val Acc: 0.4373\n",
      "epoch:  48\n",
      "Epoch 048 : Loss: 1.5287 | Val Loss: 1.5759 | Val Acc: 0.4373\n",
      "epoch:  49\n",
      "Epoch 049 : Loss: 1.5299 | Val Loss: 1.5758 | Val Acc: 0.4371\n",
      "epoch:  50\n",
      "Epoch 050 : Loss: 1.5253 | Val Loss: 1.5758 | Val Acc: 0.4369\n",
      "epoch:  51\n",
      "Epoch 051 : Loss: 1.5156 | Val Loss: 1.5758 | Val Acc: 0.4369\n",
      "epoch:  52\n",
      "Epoch 052 : Loss: 1.5315 | Val Loss: 1.5757 | Val Acc: 0.4369\n",
      "epoch:  53\n",
      "Epoch 053 : Loss: 1.5409 | Val Loss: 1.5757 | Val Acc: 0.4368\n",
      "epoch:  54\n",
      "Epoch 054 : Loss: 1.5327 | Val Loss: 1.5754 | Val Acc: 0.4369\n",
      "epoch:  55\n",
      "Epoch 055 : Loss: 1.5209 | Val Loss: 1.5750 | Val Acc: 0.4375\n",
      "epoch:  56\n",
      "Epoch 056 : Loss: 1.5152 | Val Loss: 1.5744 | Val Acc: 0.4376\n",
      "epoch:  57\n",
      "Epoch 057 : Loss: 1.5321 | Val Loss: 1.5735 | Val Acc: 0.4373\n",
      "epoch:  58\n",
      "Epoch 058 : Loss: 1.5140 | Val Loss: 1.5722 | Val Acc: 0.4376\n",
      "epoch:  59\n",
      "Epoch 059 : Loss: 1.5200 | Val Loss: 1.5705 | Val Acc: 0.4378\n",
      "epoch:  60\n",
      "Epoch 060 : Loss: 1.5227 | Val Loss: 1.5685 | Val Acc: 0.4390\n",
      "epoch:  61\n",
      "Epoch 061 : Loss: 1.5177 | Val Loss: 1.5659 | Val Acc: 0.4401\n",
      "epoch:  62\n",
      "Epoch 062 : Loss: 1.5180 | Val Loss: 1.5630 | Val Acc: 0.4406\n",
      "epoch:  63\n",
      "Epoch 063 : Loss: 1.4985 | Val Loss: 1.5599 | Val Acc: 0.4417\n",
      "epoch:  64\n",
      "Epoch 064 : Loss: 1.5081 | Val Loss: 1.5565 | Val Acc: 0.4455\n",
      "epoch:  65\n",
      "Epoch 065 : Loss: 1.4913 | Val Loss: 1.5531 | Val Acc: 0.4470\n",
      "epoch:  66\n",
      "Epoch 066 : Loss: 1.5037 | Val Loss: 1.5491 | Val Acc: 0.4474\n",
      "epoch:  67\n",
      "Epoch 067 : Loss: 1.4882 | Val Loss: 1.5444 | Val Acc: 0.4477\n",
      "epoch:  68\n",
      "Epoch 068 : Loss: 1.4728 | Val Loss: 1.5392 | Val Acc: 0.4468\n",
      "epoch:  69\n",
      "Epoch 069 : Loss: 1.4779 | Val Loss: 1.5326 | Val Acc: 0.4522\n",
      "epoch:  70\n",
      "Epoch 070 : Loss: 1.4610 | Val Loss: 1.5261 | Val Acc: 0.4557\n",
      "epoch:  71\n",
      "Epoch 071 : Loss: 1.4657 | Val Loss: 1.5176 | Val Acc: 0.4635\n",
      "epoch:  72\n",
      "Epoch 072 : Loss: 1.4391 | Val Loss: 1.5089 | Val Acc: 0.4731\n",
      "epoch:  73\n",
      "Epoch 073 : Loss: 1.4292 | Val Loss: 1.5011 | Val Acc: 0.4803\n",
      "epoch:  74\n",
      "Epoch 074 : Loss: 1.4203 | Val Loss: 1.4937 | Val Acc: 0.4848\n",
      "epoch:  75\n",
      "Epoch 075 : Loss: 1.3999 | Val Loss: 1.4854 | Val Acc: 0.4916\n",
      "epoch:  76\n",
      "Epoch 076 : Loss: 1.3972 | Val Loss: 1.4745 | Val Acc: 0.5037\n",
      "epoch:  77\n",
      "Epoch 077 : Loss: 1.3865 | Val Loss: 1.4605 | Val Acc: 0.5174\n",
      "epoch:  78\n",
      "Epoch 078 : Loss: 1.3569 | Val Loss: 1.4441 | Val Acc: 0.5280\n",
      "epoch:  79\n",
      "Epoch 079 : Loss: 1.3465 | Val Loss: 1.4269 | Val Acc: 0.5371\n",
      "epoch:  80\n",
      "Epoch 080 : Loss: 1.3424 | Val Loss: 1.4087 | Val Acc: 0.5444\n",
      "epoch:  81\n",
      "Epoch 081 : Loss: 1.3264 | Val Loss: 1.3888 | Val Acc: 0.5622\n",
      "epoch:  82\n",
      "Epoch 082 : Loss: 1.2973 | Val Loss: 1.3736 | Val Acc: 0.5769\n",
      "epoch:  83\n",
      "Epoch 083 : Loss: 1.2848 | Val Loss: 1.3623 | Val Acc: 0.5853\n",
      "epoch:  84\n",
      "Epoch 084 : Loss: 1.2478 | Val Loss: 1.3470 | Val Acc: 0.5963\n",
      "epoch:  85\n",
      "Epoch 085 : Loss: 1.2287 | Val Loss: 1.3267 | Val Acc: 0.6083\n",
      "epoch:  86\n",
      "Epoch 086 : Loss: 1.2003 | Val Loss: 1.3069 | Val Acc: 0.6167\n",
      "epoch:  87\n",
      "Epoch 087 : Loss: 1.1808 | Val Loss: 1.2884 | Val Acc: 0.6103\n",
      "epoch:  88\n",
      "Epoch 088 : Loss: 1.1614 | Val Loss: 1.2718 | Val Acc: 0.6082\n",
      "epoch:  89\n",
      "Epoch 089 : Loss: 1.1313 | Val Loss: 1.2605 | Val Acc: 0.6062\n",
      "epoch:  90\n",
      "Epoch 090 : Loss: 1.1279 | Val Loss: 1.2428 | Val Acc: 0.6145\n",
      "epoch:  91\n",
      "Epoch 091 : Loss: 1.0991 | Val Loss: 1.2190 | Val Acc: 0.6335\n",
      "epoch:  92\n",
      "Epoch 092 : Loss: 1.0819 | Val Loss: 1.1904 | Val Acc: 0.6536\n",
      "epoch:  93\n",
      "Epoch 093 : Loss: 1.0553 | Val Loss: 1.1710 | Val Acc: 0.6637\n",
      "epoch:  94\n",
      "Epoch 094 : Loss: 1.0409 | Val Loss: 1.1547 | Val Acc: 0.6669\n",
      "epoch:  95\n",
      "Epoch 095 : Loss: 1.0144 | Val Loss: 1.1484 | Val Acc: 0.6673\n",
      "epoch:  96\n",
      "Epoch 096 : Loss: 1.0034 | Val Loss: 1.1287 | Val Acc: 0.6760\n",
      "epoch:  97\n",
      "Epoch 097 : Loss: 0.9704 | Val Loss: 1.1002 | Val Acc: 0.6949\n",
      "epoch:  98\n",
      "Epoch 098 : Loss: 0.9516 | Val Loss: 1.0798 | Val Acc: 0.7048\n",
      "epoch:  99\n",
      "Epoch 099 : Loss: 0.9442 | Val Loss: 1.0672 | Val Acc: 0.7031\n",
      "epoch:  100\n",
      "Epoch 100 : Loss: 0.9127 | Val Loss: 1.0571 | Val Acc: 0.6976\n",
      "epoch:  101\n",
      "Epoch 101 : Loss: 0.9083 | Val Loss: 1.0278 | Val Acc: 0.7114\n",
      "epoch:  102\n",
      "Epoch 102 : Loss: 0.8905 | Val Loss: 0.9967 | Val Acc: 0.7309\n",
      "epoch:  103\n",
      "Epoch 103 : Loss: 0.8627 | Val Loss: 0.9913 | Val Acc: 0.7342\n",
      "epoch:  104\n",
      "Epoch 104 : Loss: 0.8482 | Val Loss: 0.9871 | Val Acc: 0.7254\n",
      "epoch:  105\n",
      "Epoch 105 : Loss: 0.8434 | Val Loss: 0.9707 | Val Acc: 0.7247\n",
      "epoch:  106\n",
      "Epoch 106 : Loss: 0.8231 | Val Loss: 0.9439 | Val Acc: 0.7421\n",
      "epoch:  107\n",
      "Epoch 107 : Loss: 0.8038 | Val Loss: 0.9219 | Val Acc: 0.7506\n",
      "epoch:  108\n",
      "Epoch 108 : Loss: 0.8055 | Val Loss: 0.9187 | Val Acc: 0.7451\n",
      "epoch:  109\n",
      "Epoch 109 : Loss: 0.7903 | Val Loss: 0.9102 | Val Acc: 0.7378\n",
      "epoch:  110\n",
      "Epoch 110 : Loss: 0.7644 | Val Loss: 0.9006 | Val Acc: 0.7512\n",
      "epoch:  111\n",
      "Epoch 111 : Loss: 0.7463 | Val Loss: 0.8968 | Val Acc: 0.7559\n",
      "epoch:  112\n",
      "Epoch 112 : Loss: 0.7468 | Val Loss: 0.8889 | Val Acc: 0.7529\n",
      "epoch:  113\n",
      "Epoch 113 : Loss: 0.7382 | Val Loss: 0.8791 | Val Acc: 0.7496\n",
      "epoch:  114\n",
      "Epoch 114 : Loss: 0.7208 | Val Loss: 0.8656 | Val Acc: 0.7547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  115\n",
      "Epoch 115 : Loss: 0.7245 | Val Loss: 0.8502 | Val Acc: 0.7622\n",
      "epoch:  116\n",
      "Epoch 116 : Loss: 0.7141 | Val Loss: 0.8381 | Val Acc: 0.7691\n",
      "epoch:  117\n",
      "Epoch 117 : Loss: 0.6993 | Val Loss: 0.8369 | Val Acc: 0.7589\n",
      "epoch:  118\n",
      "Epoch 118 : Loss: 0.6980 | Val Loss: 0.8374 | Val Acc: 0.7549\n",
      "epoch:  119\n",
      "Epoch 119 : Loss: 0.6841 | Val Loss: 0.8314 | Val Acc: 0.7598\n",
      "epoch:  120\n",
      "Epoch 120 : Loss: 0.6828 | Val Loss: 0.8201 | Val Acc: 0.7710\n",
      "epoch:  121\n",
      "Epoch 121 : Loss: 0.6860 | Val Loss: 0.8051 | Val Acc: 0.7749\n",
      "epoch:  122\n",
      "Epoch 122 : Loss: 0.6703 | Val Loss: 0.7981 | Val Acc: 0.7686\n",
      "epoch:  123\n",
      "Epoch 123 : Loss: 0.6641 | Val Loss: 0.8017 | Val Acc: 0.7617\n",
      "epoch:  124\n",
      "Epoch 124 : Loss: 0.6571 | Val Loss: 0.8106 | Val Acc: 0.7588\n",
      "epoch:  125\n",
      "Epoch 125 : Loss: 0.6506 | Val Loss: 0.8182 | Val Acc: 0.7613\n",
      "epoch:  126\n",
      "Epoch 126 : Loss: 0.6538 | Val Loss: 0.8183 | Val Acc: 0.7632\n",
      "epoch:  127\n",
      "Epoch 127 : Loss: 0.6465 | Val Loss: 0.8139 | Val Acc: 0.7667\n",
      "epoch:  128\n",
      "Epoch 128 : Loss: 0.6384 | Val Loss: 0.8055 | Val Acc: 0.7695\n",
      "epoch:  129\n",
      "Epoch 129 : Loss: 0.6278 | Val Loss: 0.7991 | Val Acc: 0.7667\n",
      "epoch:  130\n",
      "Epoch 130 : Loss: 0.6473 | Val Loss: 0.7943 | Val Acc: 0.7643\n",
      "epoch:  131\n",
      "Epoch 131 : Loss: 0.6359 | Val Loss: 0.7905 | Val Acc: 0.7669\n",
      "epoch:  132\n",
      "Epoch 132 : Loss: 0.6139 | Val Loss: 0.7906 | Val Acc: 0.7695\n",
      "epoch:  133\n",
      "Epoch 133 : Loss: 0.6329 | Val Loss: 0.7925 | Val Acc: 0.7704\n",
      "epoch:  134\n",
      "Epoch 134 : Loss: 0.6264 | Val Loss: 0.7937 | Val Acc: 0.7705\n",
      "epoch:  135\n",
      "Epoch 135 : Loss: 0.6185 | Val Loss: 0.7941 | Val Acc: 0.7721\n",
      "epoch:  136\n",
      "Epoch 136 : Loss: 0.6168 | Val Loss: 0.7929 | Val Acc: 0.7709\n",
      "epoch:  137\n",
      "Epoch 137 : Loss: 0.6126 | Val Loss: 0.7907 | Val Acc: 0.7699\n",
      "epoch:  138\n",
      "Epoch 138 : Loss: 0.6095 | Val Loss: 0.7883 | Val Acc: 0.7696\n",
      "epoch:  139\n",
      "Epoch 139 : Loss: 0.6124 | Val Loss: 0.7862 | Val Acc: 0.7691\n",
      "epoch:  140\n",
      "Epoch 140 : Loss: 0.6133 | Val Loss: 0.7843 | Val Acc: 0.7682\n",
      "epoch:  141\n",
      "Epoch 141 : Loss: 0.6099 | Val Loss: 0.7828 | Val Acc: 0.7682\n",
      "epoch:  142\n",
      "Epoch 142 : Loss: 0.6138 | Val Loss: 0.7817 | Val Acc: 0.7686\n",
      "epoch:  143\n",
      "Epoch 143 : Loss: 0.6085 | Val Loss: 0.7811 | Val Acc: 0.7682\n",
      "epoch:  144\n",
      "Epoch 144 : Loss: 0.6056 | Val Loss: 0.7808 | Val Acc: 0.7685\n",
      "epoch:  145\n",
      "Epoch 145 : Loss: 0.6085 | Val Loss: 0.7809 | Val Acc: 0.7690\n",
      "epoch:  146\n",
      "Epoch 146 : Loss: 0.6265 | Val Loss: 0.7809 | Val Acc: 0.7695\n",
      "epoch:  147\n",
      "Epoch 147 : Loss: 0.6140 | Val Loss: 0.7810 | Val Acc: 0.7699\n",
      "epoch:  148\n",
      "Epoch 148 : Loss: 0.6126 | Val Loss: 0.7811 | Val Acc: 0.7696\n",
      "epoch:  149\n",
      "Epoch 149 : Loss: 0.6196 | Val Loss: 0.7811 | Val Acc: 0.7696\n",
      "epoch:  150\n",
      "Epoch 150 : Loss: 0.6027 | Val Loss: 0.7812 | Val Acc: 0.7696\n",
      "epoch:  151\n",
      "Epoch 151 : Loss: 0.6133 | Val Loss: 0.7812 | Val Acc: 0.7696\n",
      "epoch:  152\n",
      "Epoch 152 : Loss: 0.6081 | Val Loss: 0.7812 | Val Acc: 0.7696\n",
      "epoch:  153\n",
      "Epoch 153 : Loss: 0.6161 | Val Loss: 0.7812 | Val Acc: 0.7696\n",
      "epoch:  154\n",
      "Epoch 154 : Loss: 0.6134 | Val Loss: 0.7814 | Val Acc: 0.7696\n",
      "epoch:  155\n",
      "Epoch 155 : Loss: 0.6058 | Val Loss: 0.7817 | Val Acc: 0.7696\n",
      "epoch:  156\n",
      "Epoch 156 : Loss: 0.6112 | Val Loss: 0.7822 | Val Acc: 0.7694\n",
      "epoch:  157\n",
      "Epoch 157 : Loss: 0.6153 | Val Loss: 0.7828 | Val Acc: 0.7687\n",
      "epoch:  158\n",
      "Epoch 158 : Loss: 0.6119 | Val Loss: 0.7836 | Val Acc: 0.7691\n",
      "epoch:  159\n",
      "Epoch 159 : Loss: 0.6091 | Val Loss: 0.7846 | Val Acc: 0.7700\n",
      "epoch:  160\n",
      "Epoch 160 : Loss: 0.6115 | Val Loss: 0.7850 | Val Acc: 0.7700\n",
      "epoch:  161\n",
      "Epoch 161 : Loss: 0.6092 | Val Loss: 0.7854 | Val Acc: 0.7709\n",
      "epoch:  162\n",
      "Epoch 162 : Loss: 0.6189 | Val Loss: 0.7847 | Val Acc: 0.7709\n",
      "epoch:  163\n",
      "Epoch 163 : Loss: 0.6117 | Val Loss: 0.7833 | Val Acc: 0.7708\n",
      "epoch:  164\n",
      "Epoch 164 : Loss: 0.6028 | Val Loss: 0.7814 | Val Acc: 0.7718\n",
      "epoch:  165\n",
      "Epoch 165 : Loss: 0.6034 | Val Loss: 0.7805 | Val Acc: 0.7728\n",
      "epoch:  166\n",
      "Epoch 166 : Loss: 0.6016 | Val Loss: 0.7807 | Val Acc: 0.7713\n",
      "epoch:  167\n",
      "Epoch 167 : Loss: 0.6070 | Val Loss: 0.7816 | Val Acc: 0.7704\n",
      "epoch:  168\n",
      "Epoch 168 : Loss: 0.5992 | Val Loss: 0.7825 | Val Acc: 0.7689\n",
      "epoch:  169\n",
      "Epoch 169 : Loss: 0.6001 | Val Loss: 0.7831 | Val Acc: 0.7690\n",
      "epoch:  170\n",
      "Epoch 170 : Loss: 0.6054 | Val Loss: 0.7829 | Val Acc: 0.7691\n",
      "epoch:  171\n",
      "Epoch 171 : Loss: 0.6015 | Val Loss: 0.7821 | Val Acc: 0.7687\n",
      "epoch:  172\n",
      "Epoch 172 : Loss: 0.5907 | Val Loss: 0.7794 | Val Acc: 0.7707\n",
      "epoch:  173\n",
      "Epoch 173 : Loss: 0.5870 | Val Loss: 0.7785 | Val Acc: 0.7721\n",
      "epoch:  174\n",
      "Epoch 174 : Loss: 0.5980 | Val Loss: 0.7752 | Val Acc: 0.7695\n",
      "epoch:  175\n",
      "Epoch 175 : Loss: 0.5805 | Val Loss: 0.7686 | Val Acc: 0.7701\n",
      "epoch:  176\n",
      "Epoch 176 : Loss: 0.5866 | Val Loss: 0.7628 | Val Acc: 0.7724\n",
      "epoch:  177\n",
      "Epoch 177 : Loss: 0.5850 | Val Loss: 0.7628 | Val Acc: 0.7724\n",
      "epoch:  178\n",
      "Epoch 178 : Loss: 0.5789 | Val Loss: 0.7676 | Val Acc: 0.7717\n",
      "epoch:  179\n",
      "Epoch 179 : Loss: 0.5779 | Val Loss: 0.7699 | Val Acc: 0.7741\n",
      "epoch:  180\n",
      "Epoch 180 : Loss: 0.5682 | Val Loss: 0.7662 | Val Acc: 0.7777\n",
      "epoch:  181\n",
      "Epoch 181 : Loss: 0.5721 | Val Loss: 0.7634 | Val Acc: 0.7771\n",
      "epoch:  182\n",
      "Epoch 182 : Loss: 0.5686 | Val Loss: 0.7629 | Val Acc: 0.7795\n",
      "epoch:  183\n",
      "Epoch 183 : Loss: 0.5629 | Val Loss: 0.7658 | Val Acc: 0.7801\n",
      "epoch:  184\n",
      "Epoch 184 : Loss: 0.5542 | Val Loss: 0.7705 | Val Acc: 0.7782\n",
      "epoch:  185\n",
      "Epoch 185 : Loss: 0.5514 | Val Loss: 0.7696 | Val Acc: 0.7733\n",
      "epoch:  186\n",
      "Epoch 186 : Loss: 0.5552 | Val Loss: 0.7574 | Val Acc: 0.7756\n",
      "epoch:  187\n",
      "Epoch 187 : Loss: 0.5396 | Val Loss: 0.7472 | Val Acc: 0.7786\n",
      "epoch:  188\n",
      "Epoch 188 : Loss: 0.5356 | Val Loss: 0.7455 | Val Acc: 0.7819\n",
      "epoch:  189\n",
      "Epoch 189 : Loss: 0.5409 | Val Loss: 0.7446 | Val Acc: 0.7787\n",
      "epoch:  190\n",
      "Epoch 190 : Loss: 0.5290 | Val Loss: 0.7420 | Val Acc: 0.7768\n",
      "epoch:  191\n",
      "Epoch 191 : Loss: 0.5339 | Val Loss: 0.7311 | Val Acc: 0.7811\n",
      "epoch:  192\n",
      "Epoch 192 : Loss: 0.5180 | Val Loss: 0.7334 | Val Acc: 0.7833\n",
      "epoch:  193\n",
      "Epoch 193 : Loss: 0.5253 | Val Loss: 0.7316 | Val Acc: 0.7829\n",
      "epoch:  194\n",
      "Epoch 194 : Loss: 0.5116 | Val Loss: 0.7419 | Val Acc: 0.7810\n",
      "epoch:  195\n",
      "Epoch 195 : Loss: 0.5227 | Val Loss: 0.7451 | Val Acc: 0.7840\n",
      "epoch:  196\n",
      "Epoch 196 : Loss: 0.5017 | Val Loss: 0.7418 | Val Acc: 0.7868\n",
      "epoch:  197\n",
      "Epoch 197 : Loss: 0.5005 | Val Loss: 0.7423 | Val Acc: 0.7849\n",
      "epoch:  198\n",
      "Epoch 198 : Loss: 0.5024 | Val Loss: 0.7347 | Val Acc: 0.7858\n",
      "epoch:  199\n",
      "Epoch 199 : Loss: 0.4923 | Val Loss: 0.7323 | Val Acc: 0.7872\n",
      "epoch:  200\n",
      "Epoch 200 : Loss: 0.4944 | Val Loss: 0.7323 | Val Acc: 0.7873\n",
      "epoch:  201\n",
      "Epoch 201 : Loss: 0.4936 | Val Loss: 0.7356 | Val Acc: 0.7840\n",
      "epoch:  202\n",
      "Epoch 202 : Loss: 0.4900 | Val Loss: 0.7278 | Val Acc: 0.7846\n",
      "epoch:  203\n",
      "Epoch 203 : Loss: 0.4755 | Val Loss: 0.7169 | Val Acc: 0.7902\n",
      "epoch:  204\n",
      "Epoch 204 : Loss: 0.4785 | Val Loss: 0.7122 | Val Acc: 0.7916\n",
      "epoch:  205\n",
      "Epoch 205 : Loss: 0.4704 | Val Loss: 0.7212 | Val Acc: 0.7870\n",
      "epoch:  206\n",
      "Epoch 206 : Loss: 0.4661 | Val Loss: 0.7280 | Val Acc: 0.7834\n",
      "epoch:  207\n",
      "Epoch 207 : Loss: 0.4624 | Val Loss: 0.7228 | Val Acc: 0.7881\n",
      "epoch:  208\n",
      "Epoch 208 : Loss: 0.4655 | Val Loss: 0.7123 | Val Acc: 0.7923\n",
      "epoch:  209\n",
      "Epoch 209 : Loss: 0.4620 | Val Loss: 0.6986 | Val Acc: 0.7942\n",
      "epoch:  210\n",
      "Epoch 210 : Loss: 0.4527 | Val Loss: 0.7030 | Val Acc: 0.7936\n",
      "epoch:  211\n",
      "Epoch 211 : Loss: 0.4514 | Val Loss: 0.7123 | Val Acc: 0.7892\n",
      "epoch:  212\n",
      "Epoch 212 : Loss: 0.4446 | Val Loss: 0.7177 | Val Acc: 0.7879\n",
      "epoch:  213\n",
      "Epoch 213 : Loss: 0.4397 | Val Loss: 0.7203 | Val Acc: 0.7898\n",
      "epoch:  214\n",
      "Epoch 214 : Loss: 0.4398 | Val Loss: 0.7210 | Val Acc: 0.7942\n",
      "epoch:  215\n",
      "Epoch 215 : Loss: 0.4336 | Val Loss: 0.7180 | Val Acc: 0.7973\n",
      "epoch:  216\n",
      "Epoch 216 : Loss: 0.4360 | Val Loss: 0.7169 | Val Acc: 0.7979\n",
      "epoch:  217\n",
      "Epoch 217 : Loss: 0.4398 | Val Loss: 0.7129 | Val Acc: 0.7969\n",
      "epoch:  218\n",
      "Epoch 218 : Loss: 0.4234 | Val Loss: 0.7117 | Val Acc: 0.7956\n",
      "epoch:  219\n",
      "Epoch 219 : Loss: 0.4269 | Val Loss: 0.7111 | Val Acc: 0.7946\n",
      "epoch:  220\n",
      "Epoch 220 : Loss: 0.4257 | Val Loss: 0.7070 | Val Acc: 0.7925\n",
      "epoch:  221\n",
      "Epoch 221 : Loss: 0.4236 | Val Loss: 0.7056 | Val Acc: 0.7934\n",
      "epoch:  222\n",
      "Epoch 222 : Loss: 0.4253 | Val Loss: 0.7044 | Val Acc: 0.7952\n",
      "epoch:  223\n",
      "Epoch 223 : Loss: 0.4160 | Val Loss: 0.7023 | Val Acc: 0.7970\n",
      "epoch:  224\n",
      "Epoch 224 : Loss: 0.4189 | Val Loss: 0.6995 | Val Acc: 0.7976\n",
      "epoch:  225\n",
      "Epoch 225 : Loss: 0.4153 | Val Loss: 0.6996 | Val Acc: 0.7982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  226\n",
      "Epoch 226 : Loss: 0.4158 | Val Loss: 0.6969 | Val Acc: 0.7993\n",
      "epoch:  227\n",
      "Epoch 227 : Loss: 0.4114 | Val Loss: 0.7004 | Val Acc: 0.7992\n",
      "epoch:  228\n",
      "Epoch 228 : Loss: 0.4058 | Val Loss: 0.7066 | Val Acc: 0.7992\n",
      "epoch:  229\n",
      "Epoch 229 : Loss: 0.4142 | Val Loss: 0.7114 | Val Acc: 0.7991\n",
      "epoch:  230\n",
      "Epoch 230 : Loss: 0.4098 | Val Loss: 0.7109 | Val Acc: 0.7985\n",
      "epoch:  231\n",
      "Epoch 231 : Loss: 0.4056 | Val Loss: 0.7098 | Val Acc: 0.7987\n",
      "epoch:  232\n",
      "Epoch 232 : Loss: 0.4093 | Val Loss: 0.7085 | Val Acc: 0.7976\n",
      "epoch:  233\n",
      "Epoch 233 : Loss: 0.4071 | Val Loss: 0.7064 | Val Acc: 0.7975\n",
      "epoch:  234\n",
      "Epoch 234 : Loss: 0.4061 | Val Loss: 0.7032 | Val Acc: 0.7973\n",
      "epoch:  235\n",
      "Epoch 235 : Loss: 0.4007 | Val Loss: 0.7021 | Val Acc: 0.7971\n",
      "epoch:  236\n",
      "Epoch 236 : Loss: 0.4017 | Val Loss: 0.7014 | Val Acc: 0.7982\n",
      "epoch:  237\n",
      "Epoch 237 : Loss: 0.4062 | Val Loss: 0.7009 | Val Acc: 0.7989\n",
      "epoch:  238\n",
      "Epoch 238 : Loss: 0.3982 | Val Loss: 0.7008 | Val Acc: 0.7993\n",
      "epoch:  239\n",
      "Epoch 239 : Loss: 0.3977 | Val Loss: 0.7013 | Val Acc: 0.7994\n",
      "epoch:  240\n",
      "Epoch 240 : Loss: 0.3996 | Val Loss: 0.7015 | Val Acc: 0.7994\n",
      "epoch:  241\n",
      "Epoch 241 : Loss: 0.4007 | Val Loss: 0.7020 | Val Acc: 0.7993\n",
      "epoch:  242\n",
      "Epoch 242 : Loss: 0.4066 | Val Loss: 0.7023 | Val Acc: 0.7993\n",
      "epoch:  243\n",
      "Epoch 243 : Loss: 0.4069 | Val Loss: 0.7023 | Val Acc: 0.7989\n",
      "epoch:  244\n",
      "Epoch 244 : Loss: 0.3982 | Val Loss: 0.7026 | Val Acc: 0.7982\n",
      "epoch:  245\n",
      "Epoch 245 : Loss: 0.3982 | Val Loss: 0.7030 | Val Acc: 0.7978\n",
      "epoch:  246\n",
      "Epoch 246 : Loss: 0.3938 | Val Loss: 0.7034 | Val Acc: 0.7978\n",
      "epoch:  247\n",
      "Epoch 247 : Loss: 0.3984 | Val Loss: 0.7037 | Val Acc: 0.7978\n",
      "epoch:  248\n",
      "Epoch 248 : Loss: 0.3976 | Val Loss: 0.7039 | Val Acc: 0.7976\n",
      "epoch:  249\n",
      "Epoch 249 : Loss: 0.4095 | Val Loss: 0.7039 | Val Acc: 0.7976\n",
      "epoch:  250\n",
      "Epoch 250 : Loss: 0.4125 | Val Loss: 0.7040 | Val Acc: 0.7976\n",
      "epoch:  251\n",
      "Epoch 251 : Loss: 0.4039 | Val Loss: 0.7040 | Val Acc: 0.7976\n",
      "epoch:  252\n",
      "Epoch 252 : Loss: 0.3996 | Val Loss: 0.7040 | Val Acc: 0.7976\n",
      "epoch:  253\n",
      "Epoch 253 : Loss: 0.3897 | Val Loss: 0.7041 | Val Acc: 0.7976\n",
      "epoch:  254\n",
      "Epoch 254 : Loss: 0.4012 | Val Loss: 0.7042 | Val Acc: 0.7976\n",
      "epoch:  255\n",
      "Epoch 255 : Loss: 0.4007 | Val Loss: 0.7046 | Val Acc: 0.7976\n",
      "epoch:  256\n",
      "Epoch 256 : Loss: 0.4024 | Val Loss: 0.7050 | Val Acc: 0.7979\n",
      "epoch:  257\n",
      "Epoch 257 : Loss: 0.3996 | Val Loss: 0.7057 | Val Acc: 0.7979\n",
      "epoch:  258\n",
      "Epoch 258 : Loss: 0.4077 | Val Loss: 0.7065 | Val Acc: 0.7978\n",
      "epoch:  259\n",
      "Epoch 259 : Loss: 0.3974 | Val Loss: 0.7071 | Val Acc: 0.7978\n",
      "epoch:  260\n",
      "Epoch 260 : Loss: 0.3992 | Val Loss: 0.7077 | Val Acc: 0.7980\n",
      "epoch:  261\n",
      "Epoch 261 : Loss: 0.3911 | Val Loss: 0.7081 | Val Acc: 0.7980\n",
      "epoch:  262\n",
      "Epoch 262 : Loss: 0.4140 | Val Loss: 0.7076 | Val Acc: 0.7979\n",
      "epoch:  263\n",
      "Epoch 263 : Loss: 0.4013 | Val Loss: 0.7072 | Val Acc: 0.7982\n",
      "epoch:  264\n",
      "Epoch 264 : Loss: 0.3973 | Val Loss: 0.7064 | Val Acc: 0.7982\n",
      "epoch:  265\n",
      "Epoch 265 : Loss: 0.4016 | Val Loss: 0.7055 | Val Acc: 0.7987\n",
      "epoch:  266\n",
      "Epoch 266 : Loss: 0.4001 | Val Loss: 0.7047 | Val Acc: 0.7998\n",
      "🏃 View run sedate-fawn-448 at: http://localhost:5000/#/experiments/1/runs/acf334adf26a4d5885a49e6624fe5742\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "from train import train_loop, start_tracking_experiment\n",
    "\n",
    "\n",
    "writer = start_tracking_experiment(exp_name=experiment_name, port=port, log_dir=log_dir)\n",
    "\n",
    "loaders = (train_loader, val_loader)\n",
    "train_loop(model, optimizer, criterion, scheduler, loaders, device, train_params, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212be173",
   "metadata": {},
   "source": [
    "## Stopping experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "813ab5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow server stopped (PID 234060)\n"
     ]
    }
   ],
   "source": [
    "from mlflow_server import stop_mlflow_server\n",
    "\n",
    "stop_mlflow_server(pid_file_path=pid_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general-venv)",
   "language": "python",
   "name": "general-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
